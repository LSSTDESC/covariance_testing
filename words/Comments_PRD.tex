\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{indentfirst}
\pagenumbering{gobble}
\usepackage{graphicx}

\newcommand\scott[1]{{\bf {\textcolor{teal}{[Scott: #1]}}}}
\newcommand\tassia[1]{{\bf {\textcolor{teal}{[Tassia: #1]}}}}
\newcommand\tq[1]{{\bf {\textcolor{teal}{[Tq: #1]}}}}
\newcommand\reply[1]{{\bf {\textcolor{teal}{[#1]}}}}
\newcommand\done{{\bf {\textcolor{olive}{[Done]}}}}

\renewcommand\labelitemi{--}
\renewcommand\labelenumi{\textbf{[\theenumi]}}

\begin{document}
	\thispagestyle{empty}
	
	\textbf{Journal referee review} \\
	
	In this manuscript, the authors have studied four different methods of compressing the covariant matrix's dimensionality. The four methods are:
	\begin{itemize}
		\item Retaining only the top 10\% of the smallest-variance eigenmodes
		\item Retaining only the top 10\% signal-to-noise ratio eigenmodes
		\item Using the highest signal-to-noise map from combining radial bins
		\item Using MOPED of using the covariance matrix in the parameter space, instead of the data space.
	\end{itemize}
	
	Using the DES Yr1 dataset as an example, the authors have demonstrated that compression methods 1-3 can significantly worsen the constraints for parameters that are most sensitive to the low signal-to-noise modes. The authors use $S_8$ and $A_{\text{IA}}$ as examples of such parameters. The referee recommends the authors revise the manuscript addressing the following comments that would clarify the work's scope and conclusion.
	
	\begin{enumerate}
	\item As the authors mentioned, the MOPED compression of the covariance matrix does not accelerate the speed of the analysis. In fact, the MOPED compression in eq. (11) - (13) seems to be a simple projecting the information to the parameter space. The benefit of the covariance matrix's compression is then most apparent when comparing two different covariance matrices. Is that correct? Please clarify the motivation of the work in the introduction. \\
	\reply{There have been numerous works in the literature that have used MOPED to speed up the likelihood analysis (see references [3 - 8]). In our case, we use \texttt{CosmoSIS} to calculate the theoretical $\xi_{\pm}$ vector, before compressing it to be used for the likelihood calculation. This is also the case for the other methods of compression used in this work. MOPED is superior because it is not only able to achieve maximal compression, but it is also the only compression scheme capable of reproducing the same parameter contraints as those originally obtained by DESY1. We have added a paragraph in the Introduction about the motivation for covariance matrix comparison and also modified the second last paragraph of the Conclusions to highlight the importance of our findings. }
	
	\item The motivation for comparing the two covariance matrices is unclear in the text. Perhaps the authors can expand that point. \\	
	\reply{This is now addressed in the fifth paragraph of  the Introduction.}
	
	\item The authors show $S_8$ as a parameter, but isn't it natural to use $\sigma_8$ instead of $S_8$ when one also has $\Omega_m$ as a parameter? \\
	\reply{Our analyses were done using the same settings on \texttt{CosmoSIS} as those used by Troxel $et\ al.$ (2018). Their results are displayed in the $S_8 - \Omega_m$ plane, we wanted to be cohesive by adopting the same format.}
	
	\item Methods 1-3 do not provide a competitive constraint because the parameters $S_8$ and $A_{\text{IA}}$ are most sensitive to the low signal-to-noise modes. Is the statement about $S_8$ and $A_{\text{IA}}$ specific to DESY1, or is that true in general for other cosmic shear surveys, for example, LSST or Roman? \\	
		\reply{Due to to characteristics of the intrinsic alignment parameters, we expect this to be the case for other surveys as well.}
	\end{enumerate}
	
	Besides, the following minor points need to be clarified.
	\begin{itemize}
	\item DESY1 is not defined in the main text.  \\
		\reply{It is now defined in the second paragraph of the Introduction.}
	
	\item In section II.B, the authors wrote that they set ``the lowest eigenmodes to zero." However, aren't the lowest eigenmodes of the covariance matrix the smallest noise modes?  \\
		\reply{This is similar to an analysis in terms of the principal components, instead of the eigenvalues. For a symmetric matrix, however, like the ones we are working with, they are the same thing. It is often the case that the high eigenvalues or, consequently, those with the highest principal components, are a good approximation of the full matrix. On the other hand, the lowest eigenvalues are usually just numerical noise.}
	
	\item Eq. (5) may read better with the bin indexes explicitly written. \\
		\reply{We added the $ij$ indexes to the equation.}
	
	\item Eq. (8) need further clarification, in particular, concerning the relation between $J_{0/4}$ and $\pm$. \\
		\reply{The equation has been changed to address this.}
	
	\item On page 8, the authors wrote, ``the ratio of the diagonal elements goes up to only 2.3,", but that is not consistent with Fig 10, where red dots are all below 1. \\
		\reply{The text has been corrected, we see a greater agreement, with a percentual difference of up to $17\%$, as compared to $26\%$ with the uncompressed matrices.}
	
	\item On page 9, the statement about perturbing the log of the covariance matrix is not clear. ``Introducing a 10\% error, for example, ... " sentence needs to be elaborated further. \\
	\reply{We added an equation to clarify what the resulting covariance matrix would be, and how its elements would change.}
\end{itemize}
	
\end{document}